dependencies {
    compile "log4j:log4j:${log4jVersion}"
    compile "org.slf4j:slf4j-api:1.7.12"
    compile "com.typesafe:config:1.3.0"

    // required by hadoop example mapred.WordCount
    compile "org.apache.hadoop:hadoop-client:${hadoopClientVersion}"

    compile "org.apache.spark:spark-core_${scalaMajorVersion}:${sparkVersion}"
    compile "org.apache.spark:spark-streaming_${scalaMajorVersion}:${sparkVersion}"
    compile "org.apache.spark:spark-sql_${scalaMajorVersion}:${sparkVersion}"

    compile "com.hortonworks:shc-core:1.1.0-2.1-s_2.11"
    //compile "com.hortonworks:shc-core:1.1.1-2.1-s_2.11"
}

jar {
    manifest {
        attributes (
                //"Main-Class": "com.wang.hello.spark.HelloSpark",
                "Class-Path": configurations.compile.collect { 'lib/' + it.getName() }.join(' ')
        )
    }

    // Exclude provided from compile for JAR package
    /*from {
        (configurations.compile - configurations.provided).collect { it.isDirectory() ? it : zipTree(it) }
    }*/

    // Make a JAR package with lib folder contents all dependencies
    into('lib') {
        from (configurations.compile)
    }
}